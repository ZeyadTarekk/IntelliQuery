{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj9-3U--Krvc"
      },
      "source": [
        "# This Notebook for Running the ADB Project Phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV2Nc_f8Mbqh"
      },
      "source": [
        "**This notebook is divided into two main parts, each focusing on different database sizes:**\n",
        "- **Part 1: Database Size 10K**\n",
        "  - Initiate a new database and insert vectors into it.\n",
        "  - Retrieve vectors from the database.\n",
        "  - Ensure that the insertion time for this database does not exceed 5 minutes.\n",
        "  - Allow flexible RAM usage during insertion but ensure it stays within Google Colab limits.\n",
        "  - Evaluate retrieval time and accuracy.\n",
        "  - Ensure that the peak RAM usage for retrieval does not exceed 5 MB.\n",
        "\n",
        "- **Part 2: Database Sizes 100K and More**\n",
        "  - Generate database vectors using a random seed (refer to the provided code).\n",
        "  - You have generate the database and its index before the submission.\n",
        "  - Implement a VecDB class that loads the pre-generated database, including the index, and retrieves vectors, to load the generated database.\n",
        "  - Evaluate retrieval time and accuracy for different database sizes.\n",
        "  - The Peak RAM usage for the retrieval should not exceed\n",
        "    - For 100 K --> 10 MB\n",
        "    - For 1 M --> 25 MB\n",
        "    - For 5 M --> 75 MB\n",
        "    - For 10 M --> 150 MB\n",
        "    - For 15 M --> 225 MB\n",
        "    - For 20 M --> 300 MB\n",
        "\n",
        "**This notebook is structured into two parts:**\n",
        "\n",
        "- **Part 1 - Modifiable Cells:**\n",
        "This section contains cells that teams are allowed to modify. The modification are only variables and to be submitted during the project's final phase. They are\n",
        "  - GitHub repository link (including PAT token).\n",
        "  - Database (DB) variables, providing the path to the directory or file for loading existing databases and indexes (refer to provided code to see how).\n",
        "\n",
        "- **Part 2 - Non-Modifiable Cells:** This section must not be modified by any team. It includes essential setup and evaluation code. Ensure that the notebook runs smoothly by providing the required inputs in Part 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4EV_xB6Kw17"
      },
      "source": [
        "## Part 1 - Modifiable Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AODP-iztLtBV"
      },
      "source": [
        "Of course each team will provide different github repo link\n",
        "Should include PAT token to enable me to download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TCR6Z8ABxE3w"
      },
      "outputs": [],
      "source": [
        "# username='ZiadSheriif'\n",
        "# repository='Semantic-Search-Engine'\n",
        "# git_token='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'\n",
        "# !git clone https://{git_token}@github.com/{username}/{repository}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "atNNoPovIfAt"
      },
      "outputs": [],
      "source": [
        "# %cd {repository}\n",
        "# branch_name= 'IVF+PQ'\n",
        "# !git checkout {branch_name}\n",
        "# !git pull\n",
        "# %cd {'../'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PYkO4ChtZesu"
      },
      "outputs": [],
      "source": [
        "# !pwd\n",
        "# %cd {'/content/drive/MyDrive/IVF'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsUXWYom6xRv"
      },
      "source": [
        "Teams are required to provide unique paths for the generated databases of sizes 1M, 5M, 10M, 15M, and 20M. Follow these steps to submit the databases:\n",
        "\n",
        "- Once you have the database and index ready, zip the necessary folders/files.\n",
        "- Upload the zip file to Google Drive.\n",
        "- Ensure the file is shareable with \"anyone with the link.\"\n",
        "- Obtain the zip file link (e.g., https://drive.google.com/file/d/1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah/view?usp=drive_link).\n",
        "- Extract the zip file ID (e.g., 1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah).\n",
        "- Place the ID in the designated variable (to be submitted during the project final phase).\n",
        "- The code will automatically download the zip file and unzip it inside this directory.\n",
        "- Provide the local PATH for each database to be passed to the initializer for automatic loading of the database and index (to be submitted during the project final phase)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kK46_ZVe5L3u"
      },
      "outputs": [],
      "source": [
        "TEAM_NUMBER = 9\n",
        "GDRIVE_ID_DB_100K = \"1-cXWAbGLVln8iM67iQLMHEpf2yIqZQjy\"\n",
        "GDRIVE_ID_DB_1M = \"1-dFGlgkIy04-sl7N-5Wj5oKQRmXo2VXJ\"\n",
        "GDRIVE_ID_DB_5M = \"1tHmURGUaDjrTnxDfkatPRGJYGdcoqAZH\"\n",
        "GDRIVE_ID_DB_10M = \"161u5tFGlrgf2zc-nC2GbJkYcvSxI0Buj\"\n",
        "GDRIVE_ID_DB_15M = \"1uVtt-EfFCLKyC5-h62datQDuXmk18vAu\"\n",
        "GDRIVE_ID_DB_20M = \"1xUVW6vN48WNPHe8WqthZIgjqEbVbc6NM\"\n",
        "PATH_DB_100K = \"./DataBase_100K\"\n",
        "PATH_DB_1M = \"./DataBase_1M\"\n",
        "PATH_DB_5M = \"./DataBase_5M\"\n",
        "PATH_DB_10M = \"./DataBase_10M\"\n",
        "PATH_DB_15M = \"./DataBase_15M\"\n",
        "PATH_DB_20M = \"./DataBase_20M\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGLg01fsujm"
      },
      "source": [
        "These two varaible I'll change while running in on the discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G44iH6jnObEj"
      },
      "outputs": [],
      "source": [
        "QUERY_SEED_NUMBER = 40\n",
        "DB_SEED_NUMBER = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWaZ-ByWOIcK"
      },
      "source": [
        "This means that the project submission will include these\n",
        "- TEAM_NUMBER\n",
        "- Github clone link\n",
        "- GDRIVE_ID_DB_100K\n",
        "- GDRIVE_ID_DB_1M\n",
        "- GDRIVE_ID_DB_5M\n",
        "- GDRIVE_ID_DB_10M\n",
        "- GDRIVE_ID_DB_15M\n",
        "- GDRIVE_ID_DB_20M\n",
        "- PATH_DB_100K\n",
        "- PATH_DB_1M\n",
        "- PATH_DB_5M\n",
        "- PATH_DB_10M\n",
        "- PATH_DB_15M\n",
        "- PATH_DB_20M <br>\n",
        "- And for sure the project document that describes what you did"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vr18A_htKSRl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzFTOecwu8wj"
      },
      "source": [
        "## Part 2: No edits from here\n",
        "#### You can't edit this part, and neither me.\n",
        "#### Note: Maybe I can edit if there is a major bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dqujj7tYTA1l"
      },
      "outputs": [],
      "source": [
        "# %cd Semantic-Search-Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJmXzFdisD7P"
      },
      "source": [
        "This cell to run any additional requirement that your code need <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HaPjq2hMqd20"
      },
      "outputs": [],
      "source": [
        "!pip install memory-profiler >> log.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1w6soaWFa2b8"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from utils import empty_folder\n",
        "# def clone_data(counts=[]):\n",
        "#   all=False\n",
        "#   if len(counts)==0:\n",
        "#     all=True\n",
        "\n",
        "#   if(not os.path.exists('./Data_TA')):\n",
        "#     os.mkdir('./Data_TA')\n",
        "#     print(\"Created ./Data_TA Sucessfully ...\")\n",
        "\n",
        "#   if(all or '100K' in counts):\n",
        "#     file_path='./Data_TA/data_100K.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "\n",
        "#     GDRIVE_ID_100K_TA = \"14RjiaCmrIKU-D1rU_Y2_wVrjy_Yau4bi\"\n",
        "#     !gdown $GDRIVE_ID_100K_TA -O Data_TA_100K.zip\n",
        "#     !unzip Data_TA_100K.zip\n",
        "\n",
        "#   if(all or '1M' in counts):\n",
        "#     file_path='./Data_TA/data_1M.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "#     GDRIVE_ID_1M_TA = \"1XlPBE1cS_Kc5NoAN2qo4SUurl34yCT8d\"\n",
        "#     !gdown $GDRIVE_ID_1M_TA -O Data_TA_1M.zip\n",
        "#     !unzip Data_TA_1M.zip\n",
        "\n",
        "#   if(all or '5M' in counts):\n",
        "#     file_path='./Data_TA/data_5M.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "#     GDRIVE_ID_5M_TA = \"1p2V1kT54XliJBBLa8rpzXEhyi8w7vFaL\"\n",
        "#     !gdown $GDRIVE_ID_5M_TA -O Data_TA_5M.zip\n",
        "#     !unzip Data_TA_5M.zip\n",
        "\n",
        "#   if(all or '10M' in counts):\n",
        "#     file_path='./Data_TA/data_10M.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "#     GDRIVE_ID_10M_TA = \"1Mudk6pP-2v12lkurov63JW0_KExFg36h\"\n",
        "#     !gdown $GDRIVE_ID_10M_TA -O Data_TA_10M.zip\n",
        "#     !unzip Data_TA_10M.zip\n",
        "\n",
        "#   if(all or '15M' in counts):\n",
        "#     file_path='./Data_TA/data_15M.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "#     GDRIVE_ID_15M_TA = \"1-UKG8DGyhDIZombvH-2PPe5-KZ_Jf3-_\"\n",
        "#     !gdown $GDRIVE_ID_15M_TA -O Data_TA_15M.zip\n",
        "#     !unzip Data_TA_15M.zip\n",
        "\n",
        "#   if(all or '20M' in counts):\n",
        "#     file_path='./Data_TA/data_20M.bin'\n",
        "#     if os.path.exists(file_path):\n",
        "#         # Delete the file\n",
        "#         os.remove(file_path)\n",
        "#         print(\"Removed\",file_path,'Sucessfully')\n",
        "#     GDRIVE_ID_20M_TA = \"\"\n",
        "#     !gdown $GDRIVE_ID_20M_TA -O Data_TA_20M.zip\n",
        "#     !unzip Data_TA_20M.zip\n",
        "\n",
        "# # clone_data(counts=['10M'])\n",
        "# # clone_data(counts=['100K','1M','5M','10M','15M','20M'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG0DALR498__"
      },
      "source": [
        "This cell to download the zip files and unzip them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSv2z0PVp6HA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35308845-397d-4c60-dc94-865bdac1987b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uVtt-EfFCLKyC5-h62datQDuXmk18vAu\n",
            "To: /content/saved_db_15m.zip\n",
            "  1% 42.5M/7.62G [00:01<03:10, 39.7MB/s]"
          ]
        }
      ],
      "source": [
        "# !gdown $GDRIVE_ID_DB_100K -O saved_db_100k.zip\n",
        "# !gdown $GDRIVE_ID_DB_1M -O saved_db_1m.zip\n",
        "# # !gdown $GDRIVE_ID_DB_5M -O saved_db_5m.zip\n",
        "# # !gdown $GDRIVE_ID_DB_10M -O saved_db_10m.zip\n",
        "!gdown $GDRIVE_ID_DB_15M -O saved_db_15m.zip\n",
        "# !gdown $GDRIVE_ID_DB_20M -O saved_db_20m.zip\n",
        "# !unzip saved_db_100k.zip\n",
        "# !unzip saved_db_1m.zip\n",
        "# # !unzip saved_db_5m.zip\n",
        "# # !unzip saved_db_10m.zip\n",
        "!unzip saved_db_15m.zip\n",
        "# !unzip saved_db_20m.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShuPR-gGlX3f"
      },
      "source": [
        "These are the functions for running and reporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg2vfYgeyavn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from vec_db import VecDB\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "from memory_profiler import memory_usage\n",
        "import gc\n",
        "\n",
        "@dataclass\n",
        "class Result:\n",
        "    run_time: float\n",
        "    top_k: int\n",
        "    db_ids: List[int]\n",
        "    actual_ids: List[int]\n",
        "\n",
        "results = []\n",
        "to_print_arr = []\n",
        "\n",
        "def run_queries(db, query, top_k, actual_ids, num_runs):\n",
        "    global results\n",
        "    results = []\n",
        "    for _ in range(num_runs):\n",
        "        tic = time.time()\n",
        "        db_ids = db.retrive(query, top_k)\n",
        "        toc = time.time()\n",
        "        run_time = toc - tic\n",
        "        results.append(Result(run_time, top_k, db_ids, actual_ids))\n",
        "    return results\n",
        "\n",
        "def memory_usage_run_queries(args):\n",
        "    global results\n",
        "    # This part is added to calcauate the RAM usage\n",
        "    mem_before = max(memory_usage())\n",
        "    mem = memory_usage(proc=(run_queries, args, {}), interval = 1e-3)\n",
        "    return results, max(mem) - mem_before\n",
        "\n",
        "def evaluate_result(results: List[Result]):\n",
        "    # scores are negative. So getting 0 is the best score.\n",
        "    scores = []\n",
        "    run_time = []\n",
        "    for res in results:\n",
        "        run_time.append(res.run_time)\n",
        "        # case for retireving number not equal to top_k, socre will be the lowest\n",
        "        if len(set(res.db_ids)) != res.top_k or len(res.db_ids) != res.top_k:\n",
        "            scores.append( -1 * len(res.actual_ids) * res.top_k)\n",
        "            continue\n",
        "        score = 0\n",
        "        for id in res.db_ids:\n",
        "            try:\n",
        "                ind = res.actual_ids.index(id)\n",
        "                if ind > res.top_k * 3:\n",
        "                    score -= ind\n",
        "            except:\n",
        "                score -= len(res.actual_ids)\n",
        "        scores.append(score)\n",
        "\n",
        "    return sum(scores) / len(scores), sum(run_time) / len(run_time)\n",
        "\n",
        "def get_actual_ids_first_k(actual_sorted_ids, k):\n",
        "    return [id for id in actual_sorted_ids if id < k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3bQQzzWlce4"
      },
      "source": [
        "This to generate 10K database and the query using the seed numbers that will be changed at submissions day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82Mb008w5YB7"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(DB_SEED_NUMBER)\n",
        "vectors = rng.random((10**4, 70), dtype=np.float32)\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
        "query = rng.random((1, 70), dtype=np.float32)\n",
        "\n",
        "actual_sorted_ids_10k = np.argsort(vectors.dot(query.T).T / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(query)), axis= 1).squeeze().tolist()[::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiofTQ56l1wz"
      },
      "source": [
        "Open new DB add 10K then retrieve and evaluate. Then add another 90K (total 100K) then retrieve and evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "broiY85IyDZ6"
      },
      "outputs": [],
      "source": [
        "db = VecDB()\n",
        "\n",
        "records_dict = [{\"id\": i, \"embed\": list(row)} for i, row in enumerate(vectors)]\n",
        "db.insert_records(records_dict)\n",
        "res = run_queries(db, query, 5, actual_sorted_ids_10k, 1) # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_sorted_ids_10k, 5)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"10K\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZy7uYKeFQ-K"
      },
      "source": [
        "Remove exsiting varaibles to empty some RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MreLqUWLn2uX"
      },
      "outputs": [],
      "source": [
        "del vectors\n",
        "del query\n",
        "del actual_sorted_ids_10k\n",
        "del records_dict\n",
        "del db\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrOlipAOmy9K"
      },
      "source": [
        "This code to generate 20M database. The seed (50) will not be changed. Create the same DB and prepare it's files indexes and every related file. <br>\n",
        "Note at the submission I'll not run the insert records. <br>\n",
        "The query istelf will be changed at submissions day but not the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c83ybYSKK85G"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(50)\n",
        "vectors = rng.random((10**7*2, 70), dtype=np.float32)\n",
        "\n",
        "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
        "query = rng.random((1, 70), dtype=np.float32)\n",
        "\n",
        "actual_sorted_ids_20m = np.argsort(vectors.dot(query.T).T / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(query)), axis= 1).squeeze().tolist()[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLjjjOes2Vbc"
      },
      "outputs": [],
      "source": [
        "# from utils import save_20M_record\n",
        "# # We Save the 5M file\n",
        "# save_20M_record(data=vectors)\n",
        "# del vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J00TZ55Jy03"
      },
      "outputs": [],
      "source": [
        "# # Open My Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "del vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsyBGjq9GlQj"
      },
      "outputs": [],
      "source": [
        "# Building Index\n",
        "# from utils import empty_folder\n",
        "\n",
        "# empty_folder('./DataBase_100K')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_100K.bin','./DataBase_100K/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_100K',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "#Zip and Download\n",
        "# !zip -r DataBase_100K.zip DataBase\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"./DataBase_100K.zip\")\n",
        "################################################################################\n",
        "################################################################################\n",
        "# from utils import empty_folder\n",
        "# empty_folder('./DataBase_1M')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_1M.bin','./DataBase_1M/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_1M',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "# #Zip and Download\n",
        "# !zip -r DataBase_1M.zip DataBase\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"./DataBase_1M.zip\")\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "# from utils import empty_folder\n",
        "# empty_folder('./DataBase_5M')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_5M.bin','./DataBase_5M/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_5M',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "# # # #Zip and Download\n",
        "# # !zip -r DataBase_5M.zip DataBase\n",
        "\n",
        "# # from google.colab import files\n",
        "# # files.download(\"./DataBase_5M.zip\")\n",
        "################################################################################\n",
        "################################################################################\n",
        "# from utils import empty_folder\n",
        "# empty_folder('./DataBase_10M')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_10M.bin','./DataBase_10M/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_10M',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "# # # #Zip and Download\n",
        "# !zip -r DataBase_10M.zip DataBase\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(\"./DataBase_10M.zip\")\n",
        "\n",
        "################################################################################\n",
        "################################################################################\n",
        "# from utils import empty_folder\n",
        "# empty_folder('./DataBase_15M')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_15M.bin','./DataBase_15M/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_15M',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "# # # # #Zip and Download\n",
        "# # # !zip -r DataBase_15M.zip DataBase\n",
        "\n",
        "# # # from google.colab import files\n",
        "# # # files.download(\"./DataBase_15M.zip\")\n",
        "\n",
        "# ################################################################################\n",
        "# ################################################################################\n",
        "# from utils import empty_folder\n",
        "# empty_folder('./DataBase_20M')\n",
        "# import shutil,os\n",
        "# # Add the .data file to the DataBaseFolder\n",
        "# shutil.copy('./Data_TA/data_20M.bin','./DataBase_20M/data.bin')\n",
        "\n",
        "# # import os\n",
        "# db = VecDB(file_path = './DataBase_20M',new_db=False)\n",
        "# db._build_index()\n",
        "\n",
        "\n",
        "# # # # #Zip and Download\n",
        "# # # !zip -r DataBase_20M.zip DataBase\n",
        "\n",
        "# # # from google.colab import files\n",
        "# # # files.download(\"./DataBase_20M.zip\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzkAn4AF19Jl"
      },
      "outputs": [],
      "source": [
        "print(\"Team Number\", TEAM_NUMBER)\n",
        "print(\"\\n\".join(to_print_arr))\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_100K, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**5)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"100K\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_1M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"1M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_5M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*5)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"5M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_10M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*10)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"10M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_15M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*15)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"15M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_20M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*20)\n",
        "res = run_queries(db, query, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"20M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1JSzSItQF46t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UrCA-AvWRDW"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt1_7ihfB37Z"
      },
      "outputs": [],
      "source": [
        "# print(\"Team Number\", TEAM_NUMBER)\n",
        "# print(\"\\n\".join(to_print_arr))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ### 10M\n",
        "# # Zip and Download\n",
        "# !zip -r data_10M.zip ./Data_TA/data_10M.bin\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# #### 15M\n",
        "# # Zip and Download\n",
        "# !zip -r data_10M.zip ./Data_TA/data_15M.bin\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "# ### 20M\n",
        "# # Zip and Download\n",
        "# !zip -r data_10M.zip ./Data_TA/data_20M.bin\n",
        "\n",
        "# from google.colab import files"
      ],
      "metadata": {
        "id": "wlAolNglIWyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YneWf9F0oS2J"
      },
      "outputs": [],
      "source": [
        "# !pwd\n",
        "\n",
        "#  # Cuurent Branch\n",
        "# !git branch --show-current\n",
        "\n",
        "# # Commit All Changes\n",
        "# # !git add --all\n",
        "\n",
        "# # Show Status\n",
        "# !git status\n",
        "\n",
        "# # Commit\n",
        "# # !git commit -a -m \"Debugging IVF\"\n",
        "\n",
        "# # Push\n",
        "# !git push\n",
        "\n",
        "# !git status\n",
        "\n",
        "# # Discard All Changes\n",
        "!git checkout -- .\n",
        "\n",
        "# # Pull\n",
        "# # !git pull origin {branch_name}\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# while True:pass\n",
        "# #"
      ],
      "metadata": {
        "id": "0dgE26MnFOX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}