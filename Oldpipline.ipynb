{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "no_records=100\n",
    "dim=70\n",
    "# Generate Data\n",
    "data = np.random.uniform(-1, 1, size=(no_records, dim))\n",
    "target_vector = np.random.uniform(-1, 1, size=(dim,))\n",
    "\n",
    "\n",
    "# print(\"Data\",data)\n",
    "# print(\"Target\",target_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top K\n",
    "def get_top_k_similar(target_vector,data,k=10):\n",
    "    '''\n",
    "    Data: Data Set\n",
    "    target_vector:Query\n",
    "    '''\n",
    "    similarities = cosine_similarity([target_vector], data)\n",
    "    most_similar_indices = np.argpartition(-similarities, k, axis=1)[:, :k]\n",
    "    k_most_similar_vectors = data[most_similar_indices]\n",
    "    return most_similar_indices,k_most_similar_vectors\n",
    "\n",
    "# Most Similar\n",
    "Top_k=10\n",
    "most_similar_indices,most_similar_values=get_top_k_similar(target_vector,data,k=Top_k)\n",
    "print(\"Optimal ind\",most_similar_indices)\n",
    "# print(\"Optimal values\",most_similar_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "def split_on_sign(data,target_vector,feature_no):\n",
    "    positive_subset=np.where(data[:,feature_no]>=0)[0]\n",
    "    negative_subset=np.where(data[:,feature_no]<0)[0] #take care of boundry 0\n",
    "\n",
    "    query_sign= target_vector[feature_no]>=0\n",
    "\n",
    "    subset_ind=None\n",
    "    if(query_sign):\n",
    "        subset_ind=positive_subset\n",
    "    else:\n",
    "        subset_ind=negative_subset\n",
    "    \n",
    "    subset_values = data[subset_ind]\n",
    "    return subset_ind,subset_values\n",
    "\n",
    "# Split on F0\n",
    "f0_split_ind,f0_split_values=split_on_sign(data,target_vector,0)\n",
    "print(f0_split_ind)\n",
    "# print(f0_split_values)\n",
    "\n",
    "\n",
    "\n",
    "# Split on F1\n",
    "f1_split_ind,f1_split_values=split_on_sign(data,target_vector,1)\n",
    "print(f1_split_ind)\n",
    "# print(f1_split_values)\n",
    "\n",
    "# Union of Layer 1&2\n",
    "f0_1_split_ind = list(set(f0_split_ind) | set(f1_split_ind))\n",
    "print(f0_1_split_ind)\n",
    "\n",
    "layer_1_ind=f0_1_split_ind\n",
    "\n",
    "# layer_1_ind=f0_split_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(optimal_indexes,approximate_indexes):\n",
    "# Count How many did ypu get from the Top K optimal\n",
    "    # print(most_similar_indices)\n",
    "    # print()\n",
    "    print(\"Total Number of Optimal Sol\",len(optimal_indexes))\n",
    "    print(\"Total Number of Approximate Sol\",len(approximate_indexes))\n",
    "    print(\"True Positive\",len(list(set(optimal_indexes) & set(approximate_indexes))))\n",
    "    print(\"False Positive(InCorrect pred)\",len(set(approximate_indexes)-set(optimal_indexes)))\n",
    "    print(\"False Negative(Missed)\",len(set(optimal_indexes)-set(approximate_indexes)))\n",
    "\n",
    "\n",
    "evaluate(most_similar_indices[0],layer_1_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "hyperplane=[]\n",
    "for i in range(5):\n",
    "  hyperplane.append(list(np.random.normal(loc=0,scale=1,size=data.shape[1])))\n",
    "hyperplane=np.array(hyperplane)\n",
    "#print(hyperplane)\n",
    "\n",
    "\n",
    "Hash_table=dict()\n",
    "for idx,train_data_pnt in enumerate(data):\n",
    "  Hash_key=tuple([1 if 0<=np.dot(W,train_data_pnt) else 0 for W in hyperplane])\n",
    "  #-------------------------\n",
    "  if Hash_key in Hash_table:\n",
    "    #----this will be a list\n",
    "    Hash_table[Hash_key].append(idx)\n",
    "  else:\n",
    "    Hash_table[Hash_key]=list([idx])\n",
    "\n",
    "len(Hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_points_idx=[]\n",
    "# for idx, point in enumerate(test_vec.toarray()):\n",
    "test_hash_key=tuple([1 if 0.0<=np.dot(target_vector,W) else 0 for W in hyperplane])\n",
    "if test_hash_key in Hash_table:\n",
    "  similar_points_idx.append(Hash_table[test_hash_key])\n",
    "else:\n",
    "  pass\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "consine_similarities=[]\n",
    "for i,lst in enumerate(similar_points_idx):\n",
    "  temp=[]\n",
    "  for idx in lst:\n",
    "    cos_sim=dot(target_vector.toarray()[i],train_vec.toarray()[idx])/(norm(test_vec.toarray()[i])*norm(train_vec.toarray()[idx]))\n",
    "    temp.append(cos_sim)\n",
    "  consine_similarities.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
