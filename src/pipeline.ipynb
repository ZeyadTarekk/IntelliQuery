{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from Modules.LSH import semantic_query_lsh\n",
                "# from Modules.LSH import LSH\n",
                "\n",
                "\n",
                "# import numpy as np\n",
                "# import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "# file_path = \"./random_data.txt\"\n",
                "# read_data = np.loadtxt(file_path)\n",
                "# plane_norms = LSH(read_data, 8)\n",
                "# query=[read_data[0]]\n",
                "# folder_name = \"bucket_files\"\n",
                "# result = semantic_query_lsh(query, plane_norms,folder_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "\n",
                "from utils import *\n",
                "from Modules.LSH import*\n",
                "from api import *\n",
                "from evaluation import *\n",
                "from worst_case_implementation import VecDBWorst\n",
                "\n",
                "\n",
                "datafile_path=\"../DataBase/random_data_10000.txt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_file='../DataBase/data.txt'\n",
                "Level_1_path='../DataBase/Level1'\n",
                "Level_2_path='../DataBase/Level2'\n",
                "Level_3_path='../DataBase/Level3'\n",
                "\n",
                "Level_1_nbits=8\n",
                "Level_2_nbits=3\n",
                "Level_3_nbits=3\n",
                "\n",
                "data_api = DataApi(data_file)\n",
                "data_api.generate_data_file(10000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Test LSH_index\n",
                "# Read Data From File\n",
                "read_data = data_api.get_first_k_records(10000)\n",
                "\n",
                "\n",
                "# Layer(1)\n",
                "level_1_in=read_data\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_1_planes=LSH_index(data=level_1_in, nbits=Level_1_nbits,index_path=Level_1_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Layer(2)\n",
                "# On Each Bucket Apply LSH\n",
                "\n",
                "# List all files in the directory\n",
                "files = os.listdir(Level_1_path)\n",
                "\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_2_planes={}\n",
                "\n",
                "# Loop over the files\n",
                "for file_name in files:\n",
                "    file_path = os.path.join(Level_1_path, file_name)\n",
                "    \n",
                "    if os.path.isfile(file_path):\n",
                "        # Read Data\n",
                "        read_data_2 = np.loadtxt(file_path,dtype=int,ndmin=1)\n",
                "\n",
                "        level_2_in=data_api.get_multiple_records_by_ids(read_data_2)\n",
                "        # level_2_in = array_to_dictionary(values=vectors,keys=np.hstack(read_data_2))\n",
                "\n",
                "        # # Apply LSH on this Bucket\n",
                "        level_2_planes[file_name[:-4]]=LSH_index(data=level_2_in.values(), nbits=Level_2_nbits,index_path=Level_2_path+'/' + file_name[:-4])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 136,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Layer(3)\n",
                "# On Each Bucket Apply LSH\n",
                "\n",
                "# List all files in the directory\n",
                "folders = os.listdir(Level_2_path)\n",
                "\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_3_planes={}\n",
                "# Loop over the folders\n",
                "for folder_name in folders:\n",
                "    folder_path = os.path.join(Level_2_path, folder_name)\n",
                "    files = os.listdir(folder_path)\n",
                "    # Loop over the files\n",
                "    for file_name in files:\n",
                "        file_path = os.path.join(folder_path, file_name)\n",
                "        \n",
                "        if os.path.isfile(file_path):\n",
                "            # Read Data\n",
                "            read_data_3 = np.loadtxt(file_path,dtype=int,ndmin=1)\n",
                "\n",
                "            level_3_in=data_api.get_multiple_records_by_ids(read_data_3)\n",
                "\n",
                "            # # Apply LSH on this Bucket\n",
                "            level_3_planes[file_name[:-4]]=LSH_index(data=level_3_in.values(), nbits=Level_3_nbits,index_path=Level_3_path+'/'+folder_name+'/' + file_name[:-4])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 138,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "level(1) 11100100\n",
                        "level(1) 628\n",
                        "level(2) 101\n",
                        "level(2) 401\n",
                        "level(3) 100\n",
                        "level(3) 304\n",
                        "304\n"
                    ]
                }
            ],
            "source": [
                "# Query\n",
                "query=data_api.get_record_by_id(5)[5]['embed']\n",
                "# Layer (1)\n",
                "bucket_1,index_result_1 = semantic_query_lsh(query=query,plane_norms=level_1_planes,index_path=Level_1_path)\n",
                "print(\"level(1)\",bucket_1)\n",
                "print(\"level(1)\",len(index_result_1))\n",
                "\n",
                "# Layer(2)\n",
                "bucket_2,index_result_2 = semantic_query_lsh(query=query,plane_norms=level_2_planes[bucket_1],index_path=Level_2_path+\"/\"+bucket_1)\n",
                "print(\"level(2)\",bucket_2)\n",
                "print(\"level(2)\",len(index_result_2))\n",
                "\n",
                "# Layer(3)\n",
                "bucket_3,index_result_3 = semantic_query_lsh(query=query,plane_norms=level_3_planes[bucket_2],index_path=Level_3_path+\"/\"+bucket_1+'/'+bucket_2)\n",
                "print(\"level(3)\",bucket_3)\n",
                "print(\"level(3)\",len(index_result_3))\n",
                "\n",
                "\n",
                "\n",
                "count = sum(element in index_result_2 for element in index_result_3)\n",
                "print(count)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 146,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[0.011158782057464123, 0.8096947073936462, 0.27565884590148926, 0.48038649559020996, 0.2597739100456238, 0.659046471118927, 0.37928542494773865, 0.8087599873542786, 0.8736070990562439, 0.021548112854361534, 0.9877796173095703, 0.1401907354593277, 0.7536779642105103, 0.7313639521598816, 0.7899639010429382, 0.7146242260932922, 0.6219244003295898, 0.7979387044906616, 0.7766997218132019, 0.5856465101242065, 0.34517690539360046, 0.9625859260559082, 0.26786622405052185, 0.5188780426979065, 0.9966912269592285, 0.17187891900539398, 0.49938684701919556, 0.1315959095954895, 0.3895602226257324, 0.6671280860900879, 0.2923814654350281, 0.6936476826667786, 0.7041655778884888, 0.3327277600765228, 0.7664812207221985, 0.1814052015542984, 0.15793223679065704, 0.8964231014251709, 0.7118863463401794, 0.7043396234512329, 0.6855043172836304, 0.15651613473892212, 0.7070133090019226, 0.5092920660972595, 0.5340476036071777, 0.634581983089447, 0.41931790113449097, 0.7643765211105347, 0.21819409728050232, 0.24405312538146973, 0.0847599059343338, 0.36820119619369507, 0.587044358253479, 0.036009252071380615, 0.7993974089622498, 0.8067312836647034, 0.5108171105384827, 0.15681737661361694, 0.43527111411094666, 0.3960707485675812, 0.8637329339981079, 0.07310059666633606, 0.9763832092285156, 0.9007793664932251, 0.3039684295654297, 0.8501846194267273, 0.5241423845291138, 0.5830734968185425, 0.4350626468658447, 0.5430043339729309]\n"
                    ]
                }
            ],
            "source": [
                "# query=data_api.get_first_k_records(5)[5]['embed']\n",
                "db = VecDBWorst()\n",
                "# records_np = np.random.random((10000, 70))\n",
                "records_np=data_api.get_first_k_records(10000)[1]['embed']\n",
                "print(records_np)\n",
                "# # records_dict = [{\"id\": i, \"embed\": list(row)} for i, row in enumerate(records_np)]\n",
                "# # _len = len(records_np)\n",
                "# db.insert_records(read_data)\n",
                "# res = run_queries(query,db, records_np, 5, 10)\n",
                "# print(eval(res))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}