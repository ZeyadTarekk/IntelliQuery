{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {},
            "outputs": [],
            "source": [
                "# from Modules.LSH import semantic_query_lsh\n",
                "# from Modules.LSH import LSH\n",
                "\n",
                "\n",
                "# import numpy as np\n",
                "# import os"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [],
            "source": [
                "# file_path = \"./random_data.txt\"\n",
                "# read_data = np.loadtxt(file_path)\n",
                "# plane_norms = LSH(read_data, 8)\n",
                "# query=[read_data[0]]\n",
                "# folder_name = \"bucket_files\"\n",
                "# result = semantic_query_lsh(query, plane_norms,folder_name)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "\n",
                "from utils import *\n",
                "from Modules.LSH import*\n",
                "from api import *\n",
                "from evaluation import *\n",
                "from worst_case_implementation import VecDBWorst\n",
                "\n",
                "\n",
                "datafile_path=\"../DataBase/random_data_10000.txt\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_file='../DataBase/data.txt'\n",
                "Level_1_path='../DataBase/Level1'\n",
                "Level_2_path='../DataBase/Level2'\n",
                "Level_3_path='../DataBase/Level3'\n",
                "\n",
                "Level_1_nbits=8\n",
                "Level_2_nbits=3\n",
                "Level_3_nbits=3\n",
                "\n",
                "data_api = DataApi(data_file)\n",
                "# data_api.generate_data_file(10000)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Test LSH_index\n",
                "# Read Data From File\n",
                "read_data = data_api.get_first_k_records(10000)\n",
                "\n",
                "\n",
                "# Layer(1)\n",
                "level_1_in=read_data\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_1_planes=LSH_index(data=level_1_in, nbits=Level_1_nbits,index_path=Level_1_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Layer(2)\n",
                "# On Each Bucket Apply LSH\n",
                "\n",
                "# List all files in the directory\n",
                "files = os.listdir(Level_1_path)\n",
                "\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_2_planes={}\n",
                "\n",
                "# Loop over the files\n",
                "for file_name in files:\n",
                "    file_path = os.path.join(Level_1_path, file_name)\n",
                "    \n",
                "    if os.path.isfile(file_path):\n",
                "        # Read Data\n",
                "        read_data_2 = np.loadtxt(file_path,dtype=int,ndmin=1)\n",
                "\n",
                "        level_2_in=data_api.get_multiple_records_by_ids(read_data_2)\n",
                "        # level_2_in = array_to_dictionary(values=vectors,keys=np.hstack(read_data_2))\n",
                "\n",
                "        # # Apply LSH on this Bucket\n",
                "        level_2_planes[file_name[:-4]]=LSH_index(data=level_2_in.values(), nbits=Level_2_nbits,index_path=Level_2_path+'/' + file_name[:-4])\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Layer(3)\n",
                "# On Each Bucket Apply LSH\n",
                "\n",
                "# List all files in the directory\n",
                "folders = os.listdir(Level_2_path)\n",
                "\n",
                "# TODO: Save Planes to be used in query Search\n",
                "level_3_planes={}\n",
                "# Loop over the folders\n",
                "for folder_name in folders:\n",
                "    folder_path = os.path.join(Level_2_path, folder_name)\n",
                "    files = os.listdir(folder_path)\n",
                "    # Loop over the files\n",
                "    for file_name in files:\n",
                "        file_path = os.path.join(folder_path, file_name)\n",
                "        \n",
                "        if os.path.isfile(file_path):\n",
                "            # Read Data\n",
                "            read_data_3 = np.loadtxt(file_path,dtype=int,ndmin=1)\n",
                "\n",
                "            level_3_in=data_api.get_multiple_records_by_ids(read_data_3)\n",
                "\n",
                "            # # Apply LSH on this Bucket\n",
                "            level_3_planes[file_name[:-4]]=LSH_index(data=level_3_in.values(), nbits=Level_3_nbits,index_path=Level_3_path+'/'+folder_name+'/' + file_name[:-4])\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "level(1) 01111000\n",
                        "level(1) 826\n",
                        "level(2) 010\n",
                        "level(2) 762\n",
                        "level(3) 100\n",
                        "level(3) 22\n",
                        "22\n"
                    ]
                }
            ],
            "source": [
                "# Query\n",
                "query=data_api.get_record_by_id(5)[5]['embed']\n",
                "# Layer (1)\n",
                "bucket_1,index_result_1 = semantic_query_lsh(query=query,plane_norms=level_1_planes,index_path=Level_1_path)\n",
                "print(\"level(1)\",bucket_1)\n",
                "print(\"level(1)\",len(index_result_1))\n",
                "\n",
                "# Layer(2)\n",
                "bucket_2,index_result_2 = semantic_query_lsh(query=query,plane_norms=level_2_planes[bucket_1],index_path=Level_2_path+\"/\"+bucket_1)\n",
                "print(\"level(2)\",bucket_2)\n",
                "print(\"level(2)\",len(index_result_2))\n",
                "\n",
                "# Layer(3)\n",
                "bucket_3,index_result_3 = semantic_query_lsh(query=query,plane_norms=level_3_planes[bucket_2],index_path=Level_3_path+\"/\"+bucket_1+'/'+bucket_2)\n",
                "print(\"level(3)\",bucket_3)\n",
                "print(\"level(3)\",len(index_result_3))\n",
                "\n",
                "\n",
                "\n",
                "count = sum(element in index_result_2 for element in index_result_3)\n",
                "print(count)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "ename": "IndexError",
                    "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[1;32md:\\Semantic-Search-Engine\\src\\pipeline.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m db \u001b[39m=\u001b[39m VecDBWorst()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# records_np = np.random.random((10000, 70))\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m records_np\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49marray(data_api\u001b[39m.\u001b[39;49mget_first_k_records(\u001b[39m10000\u001b[39;49m))[:][\u001b[39m'\u001b[39;49m\u001b[39membed\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(records_np)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# # records_dict = [{\"id\": i, \"embed\": list(row)} for i, row in enumerate(records_np)]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# # _len = len(records_np)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# db.insert_records(read_data)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# res = run_queries(query,db, records_np, 5, 10)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Semantic-Search-Engine/src/pipeline.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# print(eval(res))\u001b[39;00m\n",
                        "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
                    ]
                }
            ],
            "source": [
                "# query=data_api.get_first_k_records(5)[5]['embed']\n",
                "db = VecDBWorst()\n",
                "# records_np = np.random.random((10000, 70))\n",
                "records_np=np.array(data_api.get_first_k_records(10000))[:]['embed']\n",
                "print(records_np)\n",
                "# # records_dict = [{\"id\": i, \"embed\": list(row)} for i, row in enumerate(records_np)]\n",
                "# # _len = len(records_np)\n",
                "# db.insert_records(read_data)\n",
                "# res = run_queries(query,db, records_np, 5, 10)\n",
                "# print(eval(res))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
